{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural CI\n",
    "----\n",
    "In this notebook, we'll be reading in data from the data formatting notebook (dataFormmatter.ipynb) and passing them into [my neural net library](https://github.com/RobGeada/nn). Specifically, we'll design functions that allow for easy manipulation of the network architecture and dataset sizes, to simplify neural net tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,sys\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import nn\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Helpers\n",
    "We're going to wanna be able to specify dataset sizes here, so we can play around with how much data we're training and testing on, and thus we're going to want a function rather than hardcoding specific values. We also need to be able to randomly shuffle the data, as per the neural net algorithm. Finally, we're going to want a way to easily save our predictions to file, ideally allowing for comparisons to the true ci_status values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "def loadData(trainUB,testUB):\n",
    "    tX,tY = np.load(cwd+\"/formattedData/tvectors.npy\"),np.load(cwd+\"/formattedData/tstatus.npy\")\n",
    "    vX,vY = np.load(cwd+\"/formattedData/vvectors.npy\"),np.load(cwd+\"/formattedData/vstatus.npy\")\n",
    "    \n",
    "    #randomly shuffle data\n",
    "    vX2,vY2 = unison_shuffled_copies(vX,vY)\n",
    "    tX2,tY2 = unison_shuffled_copies(tX,tY)\n",
    "\n",
    "    tysize = tY2.shape\n",
    "    vysize = vY2.shape\n",
    "\n",
    "    trainX,trainY = tX2[:trainUB],tY2[:trainUB]\n",
    "    testX,testY  = vX2[:testUB],vY2[:testUB]\n",
    "\n",
    "    return trainX,trainY,testX,testY\n",
    "\n",
    "#save predictions to file\n",
    "def savePredictions(predictions,testY,filename):\n",
    "    print \"Saving predictions...\"\n",
    "    f = open(\"{}/{}_Predictions.csv\".format(cwd,filename),\"w\")\n",
    "    numPred = len(predictions)\n",
    "    for i,prediction in enumerate(predictions):\n",
    "        if round(prediction,0)!=testY[i]:\n",
    "            f.write(\"P: {},A: {} INCORRECT\".format(round(prediction,3),testY[i]))\n",
    "        else:\n",
    "            f.write(\"P: {},A: {}\".format(round(prediction,3),testY[i]))\n",
    "        if i<numPred-1:\n",
    "            f.write(\"\\n\")\n",
    "    f.close()\n",
    "    print \"Done!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup NN Test Function\n",
    "The same goes here; we're going to want to be able to play with network parameters, so let's write a function rather than hardcode anything. You'll notice that I'm passing test data into the `net.train()` function; don't be alarmed,  `net.train()` only uses testing data to produce a per-epoch glimpse at the test error, so we can nip over-fitting in the bud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nnTest(parameters):\n",
    "    #unpack parameters construct\n",
    "    trainUB,testUB,hiddenSize,epochs,learningRate = parameters\n",
    "\n",
    "    #load training,testing data from the specified sets\n",
    "    trainX,trainY,testX,testY = loadData(trainUB,testUB)\n",
    "\n",
    "    #create network\n",
    "    net = nn.Network(inDim=35,biases=1,hiddenDims=[hiddenSize,],outDim=1,learningRate=learningRate)\n",
    "\n",
    "    #train network\n",
    "    tStart = time.time()\n",
    "    Y = net.train(trainX,trainY,testX,testY,epochs=epochs)\n",
    "\n",
    "    #display training stats\n",
    "    print \"\\n===RESULTS===\"\n",
    "    print \"Train time:   {} s\".format(time.time()-tStart)\n",
    "\n",
    "    #make predictions\n",
    "    tStart = time.time()\n",
    "    predictionsX = net.predict(testX)\n",
    "    print \"Predict time: {} s\".format(time.time()-tStart)\n",
    "    \n",
    "    #test predictions and display accuracy stats\n",
    "    net.error(testX,testY,verbose=True)\n",
    "    return predictionsX,testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run It!\n",
    "Here we define the network parameters we want to test. The variables defined below correspond to network parameters as follows:\n",
    "\n",
    "\n",
    "| Variable        | Parameter           |\n",
    "| ------------- |:-------------:|\n",
    "| trainUB     | Size of training dataset|\n",
    "| testUB      | Size of testing dataset|\n",
    "| hiddenSize  | Number of nodes in hidden layer|\n",
    "| epochs  | Self-explanatory|\n",
    "| learningRate  | Eta value for neural net backpropagation|\n",
    "\n",
    "The values below are just the ones I've found to perform best on my particular slice of the dataset, so tune away!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define net parameters\n",
    "trainUB,testUB,hiddenSize,epochs,learningRate = 75000,10000,35,100,.15\n",
    "netParams = (trainUB,testUB,hiddenSize,epochs,learningRate)\n",
    "\n",
    "#test said parameters\n",
    "predictions,testY = nnTest(parameters=netParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savePredictions(predictions,testY,\"CI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX,trainY,testX,testY = loadData(500,200)\n",
    "trainX.shape, trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
